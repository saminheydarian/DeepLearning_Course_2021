{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkeDKEhdq78F"
      },
      "source": [
        "In this assignment, you will be familiar with the fundamental elements and processes in deep learning and models' training. you will: \n",
        "- Train a simple model for image classification using Tensorflow high-level APIs\n",
        "- Customize training process in deep models\n",
        "- Analyze the effect of using different activation functions in deep models\n",
        "\n",
        "Try to keep your model as simple as possible (minimum number of layers and neurons with acceptable performance).\n",
        "\n",
        "**Notes:** \n",
        "- When you submit your assignment, the output of every cell should be visible.\n",
        "- You are not eligible to change any parts of the code except the predefined sections.\n",
        "- You can add your implementation only in the predefined sections.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APr4MC1mux_2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Dense, Embedding, SimpleRNN, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "import time\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvpE5kc3zn-E"
      },
      "source": [
        "For this assignment, we consider an image classification task using fashion mnist dataset. This dataset consists of 70 thousand images, and the target is determining the category of the images. This dataset has 10 different classes. More details about the dataset are provided here (https://www.kaggle.com/zalando-research/fashionmnist).\n",
        "\n",
        "Before training our model, we need to load the dataset and pre-process it. In the following section, we load and normalize images properly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plHyaCETv6He",
        "outputId": "1aaa3dbc-3245-4f8a-da47-a164ee954324"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(data_train, label_train), (data_test, label_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "print(len(data_train), 'train samples')\n",
        "print(len(data_test), 'test samples')\n",
        "\n",
        "data_train = data_train / 255\n",
        "data_test = data_test / 255\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHh1vBKs_Zu8"
      },
      "source": [
        "num_classes = 10\n",
        "label_train = tf.keras.utils.to_categorical(label_train, num_classes)\n",
        "label_test = tf.keras.utils.to_categorical(label_test, num_classes)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aLrLDSd8jlo"
      },
      "source": [
        "hidden_units = 128"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_qUA2EW3w5W"
      },
      "source": [
        "Now that we prepare our data, we need to create the model. There are three different ways in TensorFlow that you can use for creating deep models. Sequential API, Functional API, and model sub-classing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMuhQyWZ8Q3M"
      },
      "source": [
        "# Sequential API\n",
        "This is the simplest way to make deep models in TensorFlow. You can use this API for simple models containing a stack of layers. Using this API usually is not flexible enough for customization in deep models, so we go for other APIs for customizations.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8adx58qjBJlC"
      },
      "source": [
        "In this part, we want you to implement a simple deep model for image classification using sequential API.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtqwQ4_0wBQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c56bc69f-371a-4ee6-8a07-85c67de6499c"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(keras.layers.Input(shape = data_train[0].shape))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(units=hidden_units, activation='relu'))\n",
        "model.add(keras.layers.Dense(units=10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdOGNEhsCGKY"
      },
      "source": [
        "Now we need to compile the model. Set appropriate parameters for loss function and metrics and tell us your reasons for your choices.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceiOoxR9ToOa"
      },
      "source": [
        "#### put your implementation here ####\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#### put your implementation here ####"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__AeprshToOa",
        "outputId": "104c5c9e-ef97-4fd7-9ee0-41c8fcdb6db1"
      },
      "source": [
        "history = model.fit(data_train, label_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.2, )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 5s 2ms/step - loss: 0.6749 - accuracy: 0.7633 - val_loss: 0.4416 - val_accuracy: 0.8354\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3969 - accuracy: 0.8564 - val_loss: 0.4151 - val_accuracy: 0.8527\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3516 - accuracy: 0.8731 - val_loss: 0.3610 - val_accuracy: 0.8746\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3307 - accuracy: 0.8811 - val_loss: 0.3730 - val_accuracy: 0.8764\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3185 - accuracy: 0.8850 - val_loss: 0.3823 - val_accuracy: 0.8721\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3033 - accuracy: 0.8932 - val_loss: 0.3768 - val_accuracy: 0.8782\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2929 - accuracy: 0.8970 - val_loss: 0.3878 - val_accuracy: 0.8781\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2844 - accuracy: 0.9001 - val_loss: 0.3782 - val_accuracy: 0.8842\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2738 - accuracy: 0.9046 - val_loss: 0.3567 - val_accuracy: 0.8864\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2644 - accuracy: 0.9052 - val_loss: 0.4056 - val_accuracy: 0.8806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjkcfzSaToOb"
      },
      "source": [
        "After training the model, we can evaluate it on the test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn86cDhTToOb",
        "outputId": "ee7ced19-6850-4f54-a606-627c16a1c738"
      },
      "source": [
        "model.evaluate(data_test, label_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.8698\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4390788674354553, 0.8697999715805054]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCZDoRmaEjqf"
      },
      "source": [
        "# Functional API\n",
        "As we told before, sequential API is suitable to make plain deep models. However, the cost of simplicity is the limitation. For example, you cannot create the following model using sequential API.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5f/ResNets.svg/1200px-ResNets.svg.png\" width=\"200\"/>\n",
        "\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "In this case, we can use functional API to create our models. Read more about this API on this link(https://www.tensorflow.org/guide/keras/functional) and re-implement your model (what you made in the previous section) using this API. Compile and evaluate your model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRKjLuCVyVii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47bde9d8-e2ab-4f86-ebfc-755c4581042e"
      },
      "source": [
        "#### put your implementations here ####\n",
        "img_inputs = keras.layers.Input(shape=data_train[0].shape)\n",
        "flatten_image_inputs = keras.layers.Flatten()(img_inputs)\n",
        "hidden_outputs = keras.layers.Dense(units=hidden_units, activation='relu')(flatten_image_inputs)\n",
        "outputs = keras.layers.Dense(units=10, activation='softmax')(hidden_outputs)\n",
        "\n",
        "model = keras.Model(inputs=img_inputs, outputs=outputs, name=\"fashion_mnist_model\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"fashion_mnist_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "FXWP3Pwhdvsn",
        "outputId": "4bb94d1f-a75c-4e50-8e15-09e63a432815"
      },
      "source": [
        "keras.utils.plot_model(model, \"functional_model.png\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqQ-J4DHdsnH"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YsyCyqbd6I-",
        "outputId": "d0c64a6a-ff41-41f0-efbe-88346214e03e"
      },
      "source": [
        "history = model.fit(data_train, label_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.2, )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.6617 - accuracy: 0.7707 - val_loss: 0.3961 - val_accuracy: 0.8549\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3972 - accuracy: 0.8562 - val_loss: 0.3765 - val_accuracy: 0.8673\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3520 - accuracy: 0.8726 - val_loss: 0.3958 - val_accuracy: 0.8585\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3339 - accuracy: 0.8803 - val_loss: 0.3683 - val_accuracy: 0.8773\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3168 - accuracy: 0.8893 - val_loss: 0.3771 - val_accuracy: 0.8698\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2976 - accuracy: 0.8940 - val_loss: 0.3703 - val_accuracy: 0.8761\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2907 - accuracy: 0.8985 - val_loss: 0.3684 - val_accuracy: 0.8786\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2869 - accuracy: 0.8973 - val_loss: 0.3791 - val_accuracy: 0.8832\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2758 - accuracy: 0.9046 - val_loss: 0.4023 - val_accuracy: 0.8724\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2706 - accuracy: 0.9051 - val_loss: 0.3881 - val_accuracy: 0.8871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXPAzUkwRBdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe80e4b8-a6e2-44b0-d4e1-8e5e1c348415"
      },
      "source": [
        "model.evaluate(data_test, label_test)\n",
        "#### put your implementations here ####"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4114 - accuracy: 0.8812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4113749563694, 0.8812000155448914]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u2ejvHkRTQN"
      },
      "source": [
        "# Custom training loop\n",
        "\n",
        "The fit function used in the previous sections for training models is an easy way that we usually employ to train deep models. There is another way that is more customizable and flexible to train models. In this method, we write every step of training, including feeding data to the model, calculating loss, applying gradients...\n",
        "\n",
        "This section wants you to implement a custom training loop for the model you just made in the previous section.\n",
        "\n",
        "First, we make batches of training and testing data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzgTX7WHRSXm"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((data_train, label_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((data_test, label_test))\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "# re-compile the model\n",
        "#### put your implementations here ####\n",
        "img_inputs = keras.layers.Input(shape=data_train[0].shape)\n",
        "flatten_image_inputs = keras.layers.Flatten()(img_inputs)\n",
        "hidden_outputs = keras.layers.Dense(units=hidden_units, activation='relu')(flatten_image_inputs)\n",
        "outputs = keras.layers.Dense(units=10, activation='softmax')(hidden_outputs)\n",
        "\n",
        "model = keras.Model(inputs=img_inputs, outputs=outputs, name=\"fashion_mnist_model\")\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#### put your implementations here ####"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVZKTGqVV8NX"
      },
      "source": [
        "Now let's write the custom loop.\n",
        "\n",
        "Define Optimizer, loss function, and metrics properly.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNLSRmKMV__P"
      },
      "source": [
        "#### put your implementations here ####\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop(\n",
        "    learning_rate=0.001,\n",
        "    rho=0.9,\n",
        "    momentum=0.0,\n",
        "    epsilon=1e-07,\n",
        "    centered=False,\n",
        "    name=\"RMSprop\",)\n",
        "\n",
        "loss_function = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "test_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "#### put your implementations here ####"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzIjz41WElbA",
        "outputId": "a9d370ca-e640-4719-8028-24ee688321a9"
      },
      "source": [
        "epochs = 2\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        " \n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        #### put your implementations here ####\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(x_batch_train, training=True)\n",
        "            loss_value = loss_function(y_batch_train, logits)\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "        # Update training metric.\n",
        "        train_acc_metric.update_state(y_batch_train, logits)\n",
        "\n",
        "        # Log every 100 batches.\n",
        "        if step % 100 == 0:\n",
        "            print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(loss_value))\n",
        "            )\n",
        "            print(\"Seen so far: %d samples\" % ((step + 1) * 64))\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training accuracy over epoch \" + str(epoch) + \": %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_states()\n",
        "  #### put your implementations here ####"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 2.2473\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 100: 0.6655\n",
            "Seen so far: 6464 samples\n",
            "Training loss (for one batch) at step 200: 0.7112\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 300: 0.4953\n",
            "Seen so far: 19264 samples\n",
            "Training loss (for one batch) at step 400: 0.5009\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 500: 0.6090\n",
            "Seen so far: 32064 samples\n",
            "Training loss (for one batch) at step 600: 0.5567\n",
            "Seen so far: 38464 samples\n",
            "Training loss (for one batch) at step 700: 0.4166\n",
            "Seen so far: 44864 samples\n",
            "Training loss (for one batch) at step 800: 0.4026\n",
            "Seen so far: 51264 samples\n",
            "Training loss (for one batch) at step 900: 0.5588\n",
            "Seen so far: 57664 samples\n",
            "Training loss (for one batch) at step 1000: 0.2890\n",
            "Seen so far: 64064 samples\n",
            "Training loss (for one batch) at step 1100: 0.6654\n",
            "Seen so far: 70464 samples\n",
            "Training loss (for one batch) at step 1200: 0.5065\n",
            "Seen so far: 76864 samples\n",
            "Training loss (for one batch) at step 1300: 0.1926\n",
            "Seen so far: 83264 samples\n",
            "Training loss (for one batch) at step 1400: 0.5344\n",
            "Seen so far: 89664 samples\n",
            "Training loss (for one batch) at step 1500: 0.4106\n",
            "Seen so far: 96064 samples\n",
            "Training loss (for one batch) at step 1600: 0.8108\n",
            "Seen so far: 102464 samples\n",
            "Training loss (for one batch) at step 1700: 0.3353\n",
            "Seen so far: 108864 samples\n",
            "Training loss (for one batch) at step 1800: 0.5754\n",
            "Seen so far: 115264 samples\n",
            "Training accuracy over epoch 0: 0.8199\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 0.5783\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 100: 0.1494\n",
            "Seen so far: 6464 samples\n",
            "Training loss (for one batch) at step 200: 0.3239\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 300: 0.2760\n",
            "Seen so far: 19264 samples\n",
            "Training loss (for one batch) at step 400: 0.3002\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 500: 0.3547\n",
            "Seen so far: 32064 samples\n",
            "Training loss (for one batch) at step 600: 0.3743\n",
            "Seen so far: 38464 samples\n",
            "Training loss (for one batch) at step 700: 0.1712\n",
            "Seen so far: 44864 samples\n",
            "Training loss (for one batch) at step 800: 0.4797\n",
            "Seen so far: 51264 samples\n",
            "Training loss (for one batch) at step 900: 0.1858\n",
            "Seen so far: 57664 samples\n",
            "Training loss (for one batch) at step 1000: 0.4989\n",
            "Seen so far: 64064 samples\n",
            "Training loss (for one batch) at step 1100: 0.1690\n",
            "Seen so far: 70464 samples\n",
            "Training loss (for one batch) at step 1200: 0.3025\n",
            "Seen so far: 76864 samples\n",
            "Training loss (for one batch) at step 1300: 0.1267\n",
            "Seen so far: 83264 samples\n",
            "Training loss (for one batch) at step 1400: 0.1837\n",
            "Seen so far: 89664 samples\n",
            "Training loss (for one batch) at step 1500: 0.3194\n",
            "Seen so far: 96064 samples\n",
            "Training loss (for one batch) at step 1600: 0.4951\n",
            "Seen so far: 102464 samples\n",
            "Training loss (for one batch) at step 1700: 0.4336\n",
            "Seen so far: 108864 samples\n",
            "Training loss (for one batch) at step 1800: 0.4673\n",
            "Seen so far: 115264 samples\n",
            "Training accuracy over epoch 1: 0.8640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zI4IQtxfWmv"
      },
      "source": [
        "Now implement a custom loop for evaluating your trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfLYICl6fV8a",
        "outputId": "2c097a0c-3f82-4066-8df8-c5fc9eef4460"
      },
      "source": [
        "#### put your implementations here ####\n",
        "epochs = 2\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "\n",
        "    # Run a test loop at the end of each epoch.\n",
        "    for x_batch_test, y_batch_test in test_dataset:\n",
        "        test_logits = model(x_batch_test, training=False)\n",
        "        # Update test metrics\n",
        "        test_acc_metric.update_state(y_batch_test, test_logits)\n",
        "    test_acc = test_acc_metric.result()\n",
        "    test_acc_metric.reset_states()\n",
        "    print(\"Test acc: %.4f\" % (float(test_acc),))\n",
        "#### put your implementations here ####"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Test acc: 0.8636\n",
            "\n",
            "Start of epoch 1\n",
            "Test acc: 0.8636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC6O9ectgUOB"
      },
      "source": [
        "# Analyzing the effect of using different activation functions\n",
        "\n",
        "In this part, we want you to analyze the effect of using different activation functions in deep models. \n",
        "\n",
        "As you already know, your image classification task is a multi-class classification. Based on this fact, we want you to set different activation functions (linear, softmax, or whatever you think is suitable) for the last layer (we call this layer the classifier layer) and analyze the model's predictions using these activation functions.\n",
        "\n",
        "Toward this aim, first, re-implement one of the previous models, and then, use predict function to see the prediction of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng-B5rEGNVrx"
      },
      "source": [
        "#### put your implementations here ####\n",
        "\n",
        "def create_model(activation, loss):\n",
        "  model = Sequential()\n",
        "  model.add(keras.layers.Input(shape = data_train[0].shape))\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dense(units=hidden_units, activation='relu'))\n",
        "  model.add(keras.layers.Dense(units=10, activation=activation))\n",
        "\n",
        "  model.compile(optimizer='rmsprop', loss=loss, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLwn1zbRObs"
      },
      "source": [
        "dict = {'linear':'mse',\n",
        "        'sigmoid':'binary_crossentropy',\n",
        "        'softmax':'categorical_crossentropy'}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQJP60hZeDui"
      },
      "source": [
        "import sklearn.metrics\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL16kvrPRvwT",
        "outputId": "8a0ff3c6-11e6-44f8-8c0f-0a2c93287488"
      },
      "source": [
        "confs = []\n",
        "predictions = []\n",
        "for key, value in dict.items():\n",
        "  model = create_model(key, value)\n",
        "\n",
        "  history = model.fit(data_train, label_train,\n",
        "                      epochs=10,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.2,\n",
        "                      verbose=0)\n",
        "  \n",
        "  print('model with ', key, ' activation function and ', value, ' loss function: ')\n",
        "  model.evaluate(data_test, label_test)\n",
        "  print()\n",
        "\n",
        "\n",
        "  label_pred = model.predict(data_test)\n",
        "  predictions.append(label_pred[9])\n",
        "  label_pred = np.argmax(label_pred, axis=1)\n",
        "  label_true = np.argmax(label_test, axis=1)\n",
        "\n",
        "  conf = sklearn.metrics.confusion_matrix(label_true, label_pred, normalize=None)\n",
        "  confs.append(conf)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model with  linear  activation function and  mse  loss function: \n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.8710\n",
            "\n",
            "model with  sigmoid  activation function and  binary_crossentropy  loss function: \n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0711 - accuracy: 0.8766\n",
            "\n",
            "model with  softmax  activation function and  categorical_crossentropy  loss function: \n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4230 - accuracy: 0.8740\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "lDdEWaZQfcjW",
        "outputId": "278dec2e-4fd3-4d20-cc69-9923c150cffb"
      },
      "source": [
        "plt.figure(figsize=(25,5))\n",
        "for i, key in enumerate(dict):\n",
        "  plt.subplot(1,3,i+1)\n",
        "  plt.imshow(confs[i])\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  t = key + ' + ' + dict[key]\n",
        "  plt.title(t)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABPoAAAExCAYAAADlbcx8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debRlZ1kn4N9bdZPKnJAEApmVMGQgBLJkkNgggpEITSNtOzCIA4vBdkYRBE2LDNrMKqAgKzKD0AGkwQAi0IAxyCCSMIVQmRNISMg8VNXuP/a+4eRy7626Seq7VV89z1pn1Tln77vf7wx13r1/Z+99ahiGAAAAAADbtzWrPQAAAAAA4PYT9AEAAABABwR9AAAAANABQR8AAAAAdEDQBwAAAAAdEPQBAAAAQAcEfduhqlpfVY+Yrj+3qt6w2mMCgDvSavW3zdWd7cF3YM2PV9WvLTHt0Kq6pqrW3pE1AWAlquoZVXXp1JP2W+3x7Kiq6glV9eE7YDlDVR1xR4yJbY+gbzs3DMOLhmFYdOMAALZXq9XftrW+OgzDecMw7DEMw8bVHsv2rqoeVlUXrPY4ALY3VbVTkpcn+clhGPZIcp8d9fO0qp5SVZ9arfrDMLx1GIafXK3624PVfo22BYI+bpPN7Vkw/ec6pdFwAGCbMoVKH1/tcSxna+8lWFVzW3P5W8P2OGaABg5IskuSM1d7IJsz7Xl/+GqPY2vYVnvUtjqu5fR+pISgbztXVSdX1Vum64dPu+D+UlWdV1WXVdUfzcy7pqr+sKq+WVWXV9W7qmrfmen/UFWXVNX3quqTVXX0zLRTquq1VfXBqro2yY/fgY9hfVX9flV9qaquraq/q6oDqupDVXV1VX20qu40zbtLVb1lGv+VVfXZqjpgmrb39LcXV9WFVfVnvf8HBtjeVdWzp8/sq6vqa1X1E9P9t/S36faTq+rc6fP/+QtOY3Hy1MPeMi3nP6vqnlX1nKr6dlWdX1U/ObOsA6vq/VX13ao6u6qeOjNtYd0nzdS9paduBXevqjOq6qqqet98f57p7XPT7Y9X1Quq6tPTY/1wVe0/M96V9PLfrfEwrLUz8/xMVf3HcgOtqrU1HuL8zWkMn6uqQ6ZpQ1X9elV9I8k3pvueOj3P352e9wOn+6uqXjG9RldNr9sx07STquqsafkXVtWzZuo/uqq+OK0HfKaqjp2Ztr6qnjWtU3yvqt45rTvsnuRDSQ6s8bCza6b3wclV9e7pvXNVkqdswfvj3dNyr66qz1fVfadpv19V71nwXL26ql61he8BgK1umb67rqpeWVUXTZdXTvfdM8nXpj+/sqr+JUt/nq6kF/9yVX1lmvecqnragjH+20zve0ZVnVlVu9zBz8VTZ8ZwVlXdf7p/fpt5/v7HTfcfmeR1SR48Pe4rZ567l9a4DX5pVb2uqnadqfMHNW6jXlRVv1Yzh83WuA37pqr6To3rG8+rqjXTtKfU2O9fUVWXJzm5FuytVlVHV9VHpp51aVU9d7r/AVX1r1OvvLiq/qqqdl7h87NrVb1sGtf3qupT033z6ya/WlXnJflYjVnD86Z5vz09pr2n5Sy3Df+U6fW/uqq+VVVPmKn/K9Prc0VVnVZVh81MG6rq6VX1jWmZf12jpV6jH8gzqurIGterrpzeX/91ZvmnTK/jR6axfWK+/lTrZQueq/dX1e+s5PndqoZhcNnOLknWJ3nEdP3kJG+Zrh+eZEjy+iS7JrlvkhuTHDlN/60kpyc5OMm6JH+T5O0zy/2VJHtO016Z5Isz005J8r0kD8kYEO+ymTE+JckpK3g8p2f8puigJN9O8vkk98v4zdHHkvzJNO/Tkvxjkt2SrE1yfJK9pmmnTo9p9yR3SXJGkqet9uvl4uLi4rL4Jcm9kpyf5MDp9uFJ7j5dn+1vRyW5JskJSXZO8tIkNy/ohTckOTHJXJI3JflWkj9KslOSpyb51kzdTyZ5zdRjjkvynSQPX6buf5l648uTbJivu5nH9rAkH9/C5+HjSS5McszUw96zSG+fm5n3m0nuOfX6jyd5ycyyVtTLk5yV5FEz85ya5Pc2M97fT/Kf0+tXGdc39pumDUk+kmTfaXwPT3JZkvtPY/rLJJ+c5j0xyeeS7DMt58gkd5umXZzkx6brd0py/+n6/TKuJzww43rAL2Vcj1g3TV+fsf8fOI3hK0mePvOaXLDgsZyc8b3036bnZNcteH/cnOS/Z3xvPSvje22nJHdLcm2SfaZ556axHr/a/9dcXFxchmGzffdPM26T3SXJnZN8JskLZuab7UVLfZ6upBf/dJK7T5//D01y3cxn/Zrps/jkJPdIckWS+23hY1yf5PAtmO9nM/beH5nGcESSw2amHTiN4+emz/b5/vSUJJ9asKxXJHn/1Hf2zLi9+uJp2k8luSTJ0Rm3Yd8yPZdHTNPflOR9098dnuTrSX51ptaGJL8xPae7ztaf/ubiJL+XsWftmeSB07Tjkzxo+rvDM/bD354Z8y1jWOY5+uuM6xkHZey5P5qxl8+/H96Ucb1l14zrH2cn+eEkeyT5P0nePC1n0W346W+vSnKvab67JTl6uv7YaXlHTo/heUk+s2D8H8i4DnFoxl79U8u8Rqfk1utAe07Lf27GdcuHJ7l6ZiynTLfn1wFfNfO8PyDJRUnWTLf3z/j+PWC1/4/f8nhXewAut+FF23zQd/DMvGck+fnp+leS/MTMtLtlXFmdW6TGPtOy9p5un5LkTSsY41OysqDvCTO335PktTO3fyPJe6frv5Kx6Ry7YBkHZAw1d5257xeS/Mtqv14uLi4uLotfMq5UfzvJI5LstGDabH/749z6i6ndkty0oBd+ZGb6YzIGdGun23tOPW2fJIck2Zhkz5n5Xzzfsxap+46Z+XafrbuZx/awrCzomw3rjprqrM3iQd/zZuZ9ZpJ/WmK5m+3lSZ6d5K3T9X0zrqjebTPj/VqSxy4xbcgUik23/y7JX8zc3iPjusfhGVeqv55xQ2TNguWcl3HDYK8F978204bngvE8dLq+PskTZ6b9RZLXzbwmi22YfnLm9pa8P06fmbYmtw4lP5TkqdP1Ryc5a7X/n7m4uLjMX7J83/1mkpNmbp+YZP10fWEvWurzdIt68RJje2+S35q5fXiS72bchn3OCh7j+mxZ0HfabL3NzPvF+b6XBSFSxpDw2kyB6XTfgzOFmknemCn0m3kNhunftRn7/VEz05+Waf1hqnXegrHcUj/j9u4XtvAx/HaSU2duLxv0Tf3t+iT3XWTa/Pvhh2fu++ckz5y5fa9MWUOW3obfPcmVSR6fme34adqHMgWeM+O5Lt8PY4ckJ8xMf1eSP1zsNZruOyUz60BJfixjALtm5r63Jzl5Zv7ZdcA9Mq4fHDLd/kqSR07X/2eSD96e/5t39MWhu326ZOb6dRnflElyWJJTp11Tr8z45tyY5IAaD8N5ybSL8lUZPyCTMZ2ed/5yRavqNTPLfk2SX5y/XVVf2syYL525fv0it+cfw5szfii/Y9r1+S9qPDnsYRm/Kbp4Zgx/k/EbKQC2QcMwnJ1xxfPkJN+uqnfUdFjnAgdmpgcNw3BdkssXzLOwb1w2fP8HLK6f/t1jWtZ3h2G4emb+czN+W725utcuUvcWNR7qM9+DPpDkhJk+eOVSfzeZ7bHnZuxp+y8x76J9/jb28rckeUyNh7b+jyT/bxiGizcz1kMybhAuZbbGgRkfT5JkGIZrMj6HBw3D8LEkf5Vxj4FvV9XfVtVe06yPT3JSknOnw2UePN1/WJLfW/C8HjLVmbfUetCWjndz74/Z98SmJBfM1P/7JE+crj8x43oLwDZhM333Vp/X0/XFevJytrQXp6oeVVWnT4ecXpnxM/+WfjUMw/ok/5IxVPrrpQrW+Ov0sz3h0CRfmrnvF5f40yV7WY2nC/nizDKPydI9+c4Zv4D83Mz8/zTdnyxYl1hwff+M/X7h875oz1nhY7hnVX2gxtN5XJXkRcs8hsXsn3EvwdvU76frcxl3yFl0G35ar/q5JE/PuB3/f6vq3tPfH5bkVTPP6Xczhqqzz83t7ffnT318dsxL9ftrpjFsF/1e0LdjOT/j4Tn7zFx2GYbhwiS/mHH32Eck2TvjB2oy/meaNyy38GEYnjm/3Ix7GLxtps6xy/3tlhqG4eZhGP7XMAxHZdx1+NFJnjw9thuT7D9Tc69hGI5ebnkArK5hGN42DMMJGVfohiR/vshsF2c87USS8ZwxSfa7jSUvSrJvVe05c9+hGQ/fWazuITN1d1uu7jAML5npg4/O+G3yPjP3LeeQmeuHZvwW/LLN/M1CK+7l0zrAvyb5mSRPypatqJ6f8XCrpczWuCjjazsOZAwU98v0fA/D8OphGI7PuBfjPTMeFpxhGD47DMNjM35h996M39TP137hgnWZ3YZhePsWjHup9ZiF493c+2P2PbEm43vzoumu9yY5tsZzDT46yVu3YFwAzSzTd2/1eZ3xs++iLG7Z7cLNqap1GY/iemnGwx33SfLBzPSrqvrpjHvG/XOS/73Usobx1+lne+15Gfccm7/vbUv86aK9bDoP2+sz7qW137TML8+MbeFjvyxjiHn0TM29h/HXiZMF6zC5db+/LGO/X/i8z/ac5Z7r8zMeKruY1yb5apJ7DMOwV8ZDVGuJeRdzWcZDsW9Tv8/4ODYkuXSZbfgMw3DaMAyPzHi04VczPvfzj+1pC/r9rsMwfGYLxr6l/f6QqY/Pjnmpfr9HxiMf5v9PvCXJY2s8T++RGfv/NkPQt2N5XZIXzpxE8s5V9dhp2p4Zg7LLM34j8aLVGeLyqurHq+o+NZ44/KqMH4ybpr0PPpzkZVW1V40nA717VT10VQcMwJKq6l5V9fBphf+GjCvKmxaZ9d0Z9zr70RpPJH1yVrayeothGM7PePjIi2s8OfSxSX414wrbYnUfXVUnTHX/NFtv3emJVXXUFCb+aZJ3z+wFsaVuay9/U5I/SHKfjOfU2Zw3JHlBVd2jRsdW1VIB6NuT/HJVHTe9zi9K8m/DMKyvqh+pqgdOe+Zfm/E9sKmqdq6qJ1TV3sMw3Jyx38+/L16f5OnT31VV7V5VP70gmFvKpUn2q+nk4IvZwvfH8TX+aMlcxj1jbsx4XqsMw3BDxvfN25KcMQzDeVswLoAmNtN3357kedM24v4ZT1+xWG9MtuDzdDN2znjes+8k2VBVj0oy+0Md+2fsNb+W8Vysj6mqk25jraW8Icmzqur4qZ8cMW0n754xEPrONJZfzrhH37xLkxw8rRfM79n9+iSvqKq7TH9zUFWdOM3/rox98Mipxz9/fkFTn39Xxm30Paf6v5uln/eFPpDkblX12zX+IMieVfXAadqeGfvnNdNecs9YyZMzPa43Jnl5jT+2sraqHjy9dxbz9iS/U1U/NIViL0ryzmEYNiy1DV/jD3A+dvoS8MaMh3rPvx9fl+Q5Nf2oWI0/WvKzWzj8W71GS/i3jHsB/kFV7VRVD8t4uPk7ZuY5aWYd8AUZT91x/vT8XJDksxm/IH3PMAzXZxsi6NuxvCrjSUI/XFVXZ1wpnf8geFPGXVUvzHhi7tNXZYSbd9eMK9BXZTz0+BP5/t4HT87YNM7KeMLWd2f8ZgCAbdO6JC/J+K3xJRn33nrOwpmGYTgz4/la35Hxm/FrMp5j6MbbWPcXMu7tdlHGH5/4k2EYPrpE3V/PGNpcnLG3XHAba27OmzOeD+aSjIfK/OZtWMZt7eWnZjq9x3RY9Oa8POOGyYcz9uO/y3gi7h8wPa/Pz7jnxsUZ9wz4+WnyXhk3jq6Yxn15vr/XxpOSrJ8ON3p6kidMy/v3jCd0/6vp787OeC6ezRqG4asZN0TOmQ4FWuqQtM29P96X8VCjK6Zx/swUSM77+4yh6TZ1GA9Alu+7f5bk35N8KeMPLn1+uu8HrODzdFHT6RF+M2MvuSLjHunvn5nlb5O8bxiGDw7DcHnGL1zesMyXSis2DMM/JHlhxh5/dcY9svYdhuGsJC/LuLf7pRk/zz8986cfS3Jmkkuqan7P+2dn7EenT33roxnPUZdhGD6U5NUZD0M+O9/vzfPrML+R8cuuc5J8ahrPG7fwMVyd5JEZA6pLMv7a/Y9Pk5+V8Xm9OmOvfeeWLHOBZ2V8L3w242Grf56lM6Q3Zux7n8z4Iyw3ZHxsydLb8GsyBpsXTct/aKZAchiGU6d675ie0y8nedQWjnux1+hWhmG4KePz9qiM/x9ek+TJ03t73tuS/Mk0tuPz/UN1522z/b6G4XbtdQsA0NT0TfGVGQ9H+dZqj6cHVfXNjIfI/EDgyfdV1ckZT16+cGV/dp5DMx5+dNdhGK5qNTYAtn1VdWTG0GrdMAwbVns8LK6qTsn4gzPPW2ae/5Jx78vDhm0sWLNHHwCwzauqx1TVbtPhHS/N+A3z+tUdVR+q6vEZD1P62GqPZXtX47l+fjfjL/UJ+QBIVT1uOrT2Thn3UvtHId/2bTrtyG8lecO2FvIlgj4AYPvw2IyHdlyU5B5Jfn5bXLHa3lTVxzOesPvXZ395rqo+VFXXLHJ57qoNdhs3hdBXZTyM6k9WeTgAbDuelvGUI99MsjErPF/e1lRVZy7R75+w2mPbVk17ZV6Z8TRhr1zl4SzKobsAAAAA0AF79AEAAABAB1YU9FXVP22tgQB98/kB7fj/BtxWPj+gHf/fgNtquc+PFR26u+uec8NdDtv1DhnU5lxx5k5N6qyGWru2Wa1h48ZmtVqqdTs3qzXceFOzWkmSqna1Gh66f3WuuGoYhr2bFYQd2C577DTsd9juTWpdfVbDgwMafjwmSa3Rr2+v2mVds1rDDTc2q9Uz/Rra2X3PtcNBh7fZrrnky22245O03Z5prdNTn9VO7fKX4eabm9Xq2XL9em4lC7rLYbvm2e8+/o4Z1WacetSdm9RJkjRckU+StXvv1azWxiuuaFarpbmDD29Wa8M565vVSpLaqWGIeXO7EPOjw7u/0awY7OD2O2z3POOdJzSp9Ylj22041NyKVltutzV7tAlLk2Tj9xr+QGvDjZS1R9yrWa2NZ36tWa0kbdcfN7ULgvVraOegw3fOq9/3Q01qveyIo5vUSZJa1+5LniTJpnZ9bdjQMKRq2K/n7npQs1obLriwWa0k3e5Is1y/do4+AAAAAOiAoA8AAAAAOiDoAwAAAIAOCPoAAAAAoAOCPgAAAADogKAPAAAAADog6AMAAACADgj6AAAAAKADgj4AAAAA6ICgDwAAAAA6IOgDAAAAgA4I+gAAAACgA4I+AAAAAOiAoA8AAAAAOiDoAwAAAIAOCPoAAAAAoAOCPgAAAADogKAPAAAAADog6AMAAACADgj6AAAAAKADgj4AAAAA6ICgDwAAAAA6IOgDAAAAgA4I+gAAAACgA3MrmfmKM3fKqUfdeWuN5VZOveCMJnWS5HEHP6BZrSQZbrqpab0ebThn/WoPYasZbvb+AG6fq89ak08cu2uTWl336xtubFqvRxvP+vpqD2Hr2bRxtUcAbOcu+fKuedkRRzepddpFX2xSJ0lOPPC4ZrWSpOZWFGvcPsPQrlZDGy64cLWHsPV0+potxx59AAAAANABQR8AAAAAdEDQBwAAAAAdEPQBAAAAQAcEfQAAAADQAUEfAAAAAHRA0AcAAAAAHRD0AQAAAEAHBH0AAAAA0AFBHwAAAAB0QNAHAAAAAB0Q9AEAAABABwR9AAAAANABQR8AAAAAdEDQBwAAAAAdEPQBAAAAQAcEfQAAAADQAUEfAAAAAHRA0AcAAAAAHRD0AQAAAEAHBH0AAAAA0AFBHwAAAAB0QNAHAAAAAB0Q9AEAAABABwR9AAAAANABQR8AAAAAdGBuRXNXpXbaeSsN5dYed/ADmtRJkod+6fpmtZLkE8etbVZr7vBDm9XasP68ZrXmDj6oWa0NF1zYrFaSpKpdrWFoVwtopyq1bl2TUi379YP+4+ZmtZLk9Pu169drj7xHs1obz/p6s1pr99u3Wa2Nl13erFYS/Rq43WrNmqzZdbcmtU488LgmdZLkN8/+arNaSfKX9z6mWa25ux7QrNaGSy5tVqvVemOSDDfe2KxWkh2yX9ujDwAAAAA6IOgDAAAAgA4I+gAAAACgA4I+AAAAAOiAoA8AAAAAOiDoAwAAAIAOCPoAAAAAoAOCPgAAAADogKAPAAAAADog6AMAAACADgj6AAAAAKADgj4AAAAA6ICgDwAAAAA6IOgDAAAAgA4I+gAAAACgA4I+AAAAAOiAoA8AAAAAOiDoAwAAAIAOCPoAAAAAoAOCPgAAAADogKAPAAAAADog6AMAAACADgj6AAAAAKADgj4AAAAA6ICgDwAAAAA6IOgDAAAAgA4I+gAAAACgA3OrPYBtwSfuu1vTei845/Rmtf743ic0q9XScP31qz0EgG3bpqFNnao2dZKc8cA9m9VKkj86u12/fnHjdZFWhus67tdDo/9jQN8a9dGaa7fp/5dH37dZrSR5/tf/tVmtPzumz+3rbNy42iPgDmSPPgAAAADogKAPAAAAADog6AMAAACADgj6AAAAAKADgj4AAAAA6ICgDwAAAAA6IOgDAAAAgA4I+gAAAACgA4I+AAAAAOiAoA8AAAAAOiDoAwAAAIAOCPoAAAAAoAOCPgAAAADogKAPAAAAADog6AMAAACADgj6AAAAAKADgj4AAAAA6ICgDwAAAAA6IOgDAAAAgA4I+gAAAACgA4I+AAAAAOiAoA8AAAAAOiDoAwAAAIAOCPoAAAAAoAOCPgAAAADogKAPAAAAADowt6K5hyHDzTdtpaGsnrVH3bNpvZPvv0+zWvt+rFmpXP6QG9sV27fdc5jLv9uuVpIMQ9t6QH867ddr7nZA03ovPuZHm9V65BkXNqt12jF7NatVe+7RrFauu65dLYA7wLBpUzZde+1qD+MOt+kh92la74XHrWtW68CPbWpW64IHNSuV2nnnZrWGDRua1RoL7njb1/boAwAAAIAOCPoAAAAAoAOCPgAAAADogKAPAAAAADog6AMAAACADgj6AAAAAKADgj4AAAAA6ICgDwAAAAA6IOgDAAAAgA4I+gAAAACgA4I+AAAAAOiAoA8AAAAAOiDoAwAAAIAOCPoAAAAAoAOCPgAAAADogKAPAAAAADog6AMAAACADgj6AAAAAKADgj4AAAAA6ICgDwAAAAA6IOgDAAAAgA4I+gAAAACgA4I+AAAAAOiAoA8AAAAAOiDoAwAAAIAOCPoAAAAAoANzqz2AbcHGM7+22kPYai5/SLtabz7/081qPemQZqWydq+92hVLsvGqq5rVqp12blYrN7UrBfRpw7fOXe0hbDWnHdOu13zwws83q3XSQfdvVqvm2q7WDhs2NKvV9LHd3K4U0Kc1n/hC03obG9a64EHtar3ngtOb1Xr8we0e2JpddmlWK0k23XBDs1rbSr+2Rx8AAAAAdEDQBwAAAAAdEPQBAAAAQAcEfQAAAADQAUEfAAAAAHRA0AcAAAAAHRD0AQAAAEAHBH0AAAAA0AFBHwAAAAB0QNAHAAAAAB0Q9AEAAABABwR9AAAAANABQR8AAAAAdEDQBwAAAAAdEPQBAAAAQAcEfQAAAADQAUEfAAAAAHRA0AcAAAAAHRD0AQAAAEAHBH0AAAAA0AFBHwAAAAB0QNAHAAAAAB0Q9AEAAABABwR9AAAAANABQR8AAAAAdEDQBwAAAAAdmFvJzLXLuqz94XtsrbHcysavfKNJnSSZO+TgZrWSZPjeVe2K7bxTs1JPOuQhzWpt+OihzWrlEee1q5VkzW67Nau16brrmtUC2ql1O2fu4MOb1NpwzvomdZJk7RE/1KxWkgwXf7tZrTX77N2s1kkHNSuVmz5yWLNaOz/y3Ga1kqTmVrQafbsMGzY0qwU0tMeu2XS/45qUWvOpLzapkyRrjr13s1pJkm+e36xUy379+IMf1KzW2W++X7NaRzzpC81qJTtmv7ZHHwAAAAB0QNAHAAAAAB0Q9AEAAABABwR9AAAAANABQR8AAAAAdEDQBwAAAAAdEPQBAAAAQAcEfQAAAADQAUEfAAAAAHRA0AcAAAAAHRD0AQAAAEAHBH0AAAAA0AFBHwAAAAB0QNAHAAAAAB0Q9AEAAABABwR9AAAAANABQR8AAAAAdEDQBwAAAAAdEPQBAAAAQAcEfQAAAADQAUEfAAAAAHRA0AcAAAAAHRD0AQAAAEAHBH0AAAAA0AFBHwAAAAB0QNAHAAAAAB2YW8nMww03ZuNXvrG1xrJqNpx/wWoPoQ9VzUrNPeK8ZrVOu+iLzWolyYkHHtesVu20c7NaualdKdjRDTfelA3nrF/tYdzhNp79rdUewlaz6dprm9Vas9tuzWrt/Mhzm9V6zbmfalYrSZ552AnNaq29052a1cp325WCHd4112fNp9pua7Sw6UtfXe0hbDUt+3XLbbUjnvSFZrVOveCMZrWS5HEHP6BZrTW77NKsVq5fZhztRgEAAAAAbC2CPgAAAADogKAPAAAAADog6AMAAACADgj6AAAAAKADgj4AAAAA6ICgDwAAAAA6IOgDAAAAgA4I+gAAAACgA4I+AAAAAOiAoA8AAAAAOiDoAwAAAIAOCPoAAAAAoAOCPgAAAADogKAPAAAAADog6AMAAACADgj6AAAAAKADgj4AAAAA6ICgDwAAAAA6IOgDAAAAgA4I+gAAAACgA4I+AAAAAOiAoA8AAAAAOiDoAwAAAIAOCPoAAAAAoAOCPgAAAADogKAPAAAAADowt9oD2CFVtas1DH3WWrO2WakTD7pfs1pJctpFX2hW68QDj2tWC4BlNFw32HTddc1qtfTMw3+saT39GrjdKqm5Npvkw4YNTeokabu9m7TdDm1ouPmm1R7CVvG4Qx7YtN4HL/xcs1onHXT/ZrWWY48+AAAAAOiAoA8AAAAAOiDoAwAAAIAOCPoAAAAAoAOCPgAAAADogKAPAAAAADog6AMAAACADgj6AAAAAKADgj4AAAAA6ICgDwAAAAA6IOgDAAAAgA4I+gAAAACgA4I+AAAAAOiAoA8AAAAAOiDoAwAAAIAOCPoAAAAAoAOCPgAAAADogKAPAAAAADog6AMAAACADgj6AAAAAKADgj4AAJ21qdsAAAHtSURBVAAA6ICgDwAAAAA6IOgDAAAAgA4I+gAAAACgA4I+AAAAAOiAoA8AAAAAOjC32gPYIQ3Dao9g66hqV2vTxmal1t7pTs1qJcmJBx7XrNZbz/90s1oHHNysFMD2p+W6wZq17Wo17Ndr1q1rVitp26/ff+Fnm9Xa7cBmpYAhGTZsWO1R3PF63d5treX2dcPXbO3eezWrlSQnHXT/ZrXecf5nmtXaf5nta3v0AQAAAEAHBH0AAAAA0AFBHwAAAAB0QNAHAAAAAB0Q9AEAAABABwR9AAAAANABQR8AAAAAdEDQBwAAAAAdEPQBAAAAQAcEfQAAAADQAUEfAAAAAHRA0AcAAAAAHRD0AQAAAEAHBH0AAAAA0AFBHwAAAAB0QNAHAAAAAB0Q9AEAAABABwR9AAAAANABQR8AAAAAdEDQBwAAAAAdEPQBAAAAQAcEfQAAAADQAUEfAAAAAHRA0AcAAAAAHRD0AQAAAEAHBH0AAAAA0IEahmHLZ676TpJzt95wgI4dNgzDnVd7ELAj0K+B20G/hkb0a+B2WLJfryjoAwAAAAC2TQ7dBQAAAIAOCPoAAAAAoAOCPgAAAADogKAPAAAAADog6AMAAACADgj6AAAAAKADgj4AAAAA6ICgDwAAAAA6IOgDAAAAgA78f3geUKLCHiJRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1800x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZVHMF3XmUei",
        "outputId": "d8ba9af9-41e8-4c34-840f-b2694ab4ae76"
      },
      "source": [
        "for i, key in enumerate(dict):\n",
        "  print('Confusion matrix for: ', key, ' + ', dict[key])\n",
        "  print()\n",
        "  print(confs[i])\n",
        "  print()\n",
        "  print('--------------------------------------------------')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix for:  linear  +  mse\n",
            "\n",
            "[[821   3   9  49   3   0  99   0  16   0]\n",
            " [  3 958   3  31   2   0   1   0   2   0]\n",
            " [ 19   1 797  10  90   0  79   0   4   0]\n",
            " [ 18   2   4 896  22   0  51   0   6   1]\n",
            " [  0   0 124  46 724   0 104   0   2   0]\n",
            " [  0   0   0   0   0 940   0  40   1  19]\n",
            " [117   0  81  39  57   0 679   0  27   0]\n",
            " [  0   0   0   0   0   5   0 977   0  18]\n",
            " [  0   0   1   4   3   0  11   6 975   0]\n",
            " [  0   0   0   0   0   7   1  48   1 943]]\n",
            "\n",
            "--------------------------------------------------\n",
            "Confusion matrix for:  sigmoid  +  binary_crossentropy\n",
            "\n",
            "[[800   3  14  44   4   1 124   0  10   0]\n",
            " [  2 963   1  25   4   0   4   0   1   0]\n",
            " [ 20   2 788   9 122   0  55   0   4   0]\n",
            " [ 18   5  24 886  35   0  29   0   3   0]\n",
            " [  1   1  92  30 810   0  63   0   3   0]\n",
            " [  0   0   0   1   0 973   0  12   2  12]\n",
            " [ 99   1 103  34  73   0 675   0  15   0]\n",
            " [  0   0   0   0   0  28   0 924   1  47]\n",
            " [  1   0   1   3   7   1   3   4 980   0]\n",
            " [  0   0   0   0   0   9   1  23   0 967]]\n",
            "\n",
            "--------------------------------------------------\n",
            "Confusion matrix for:  softmax  +  categorical_crossentropy\n",
            "\n",
            "[[871   1  20  17   6   1  77   0   7   0]\n",
            " [  1 977   2  15   2   0   2   0   1   0]\n",
            " [ 29   0 864  12  67   1  20   1   6   0]\n",
            " [ 33  12  20 888  28   0  15   0   4   0]\n",
            " [  3   0 185  41 737   2  30   0   2   0]\n",
            " [  1   0   0   1   0 957   0  24   3  14]\n",
            " [179   1 133  32  74   0 569   0  12   0]\n",
            " [  0   0   0   0   0  18   0 959   0  23]\n",
            " [ 12   0   7   2   2   2   0   5 970   0]\n",
            " [  0   0   0   0   0   7   1  44   0 948]]\n",
            "\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tV9X_jO2GoC"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "JEK6o25Fz1dd",
        "outputId": "e3ceacff-cce3-4d72-90b3-8bcebdca3a89"
      },
      "source": [
        "for i, key in enumerate(dict):\n",
        "  print('Prediction for activation function', key, ' :')\n",
        "  print(predictions[i])\n",
        "  print('------------------------------------------------------------')\n",
        "plt.figure(figsize=(25,5))\n",
        "plt.imshow(data_test[9], cmap ='gray')\n",
        "print(label_test[9])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction for activation function linear  :\n",
            "[-0.00263143 -0.00796274 -0.01925065 -0.00943992 -0.0081144  -0.04263551\n",
            " -0.01082398  1.0844814  -0.00498062  0.00676251]\n",
            "------------------------------------------------------------\n",
            "Prediction for activation function sigmoid  :\n",
            "[5.5170175e-20 5.3388817e-19 6.6337853e-19 1.0529273e-16 6.9855701e-17\n",
            " 3.2872063e-06 6.7715474e-18 9.9990523e-01 1.7442957e-07 1.2173721e-09]\n",
            "------------------------------------------------------------\n",
            "Prediction for activation function softmax  :\n",
            "[6.8720373e-14 2.3416964e-16 1.6353407e-17 3.0392138e-16 7.4454592e-20\n",
            " 3.4239183e-06 4.9872077e-16 9.9999654e-01 1.3923876e-09 9.7271835e-10]\n",
            "------------------------------------------------------------\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}